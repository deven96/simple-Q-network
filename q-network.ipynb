{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Q Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def one_hot(length, idx):\n",
    "    encode = np.zeros(shape=[length])\n",
    "    encode[idx] = 1.\n",
    "    return encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "env_name = 'FrozenLake8x8-v0'\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenLake8x8 has 64 states & 4 actions\n"
     ]
    }
   ],
   "source": [
    "n_states = env.env.nS\n",
    "n_actions = env.env.nA\n",
    "print(f'{env_name.replace(\"-v0\", \"\")} has {n_states:,} states & {n_actions:,} actions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# inputs & targets (states & actions)\n",
    "inputs = tf.placeholder(tf.float32, shape=[n_states])\n",
    "target = tf.placeholder(tf.float32, shape=[1, n_actions])\n",
    "\n",
    "# reshape\n",
    "X_reshape = tf.reshape(inputs, shape=[1, n_states])\n",
    "\n",
    "# weights\n",
    "weight = tf.Variable(tf.random_normal(shape=[n_states, n_actions], mean=0, stddev=0.4))\n",
    "\n",
    "# Q value prediction\n",
    "Q_value = tf.matmul(X_reshape, weight)\n",
    "predict = tf.argmax(Q_value, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.squared_difference(target, Q_value))\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-1)\n",
    "train = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "### Tensorflow's `Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dir = f'saved/{env_name}/'\n",
    "tensorboard_dir = os.path.join(save_dir, 'tensorboard')\n",
    "logdir = os.path.join(tensorboard_dir, 'summary')\n",
    "model_dir = os.path.join(save_dir, 'models/')\n",
    "model_path = os.path.join(model_dir, 'model.ckpt')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)\n",
    "\n",
    "tf.summary.scalar('loss', loss)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Attempting to load latest checkpoint\n",
      "INFO:tensorflow:Restoring parameters from saved/FrozenLake8x8-v0/models/model.ckpt-259347\n",
      "INFO: Successfully loaded ckeckpoint – saved/FrozenLake8x8-v0/models/model.ckpt-259347\n"
     ]
    }
   ],
   "source": [
    "if tf.gfile.Exists(model_dir):\n",
    "    try:\n",
    "        sys.stdout.write('INFO: Attempting to load latest checkpoint\\n')\n",
    "        last_ckpt = tf.train.latest_checkpoint(model_dir)\n",
    "        saver.restore(sess=sess, save_path=last_ckpt)\n",
    "        sys.stdout.write(f'INFO: Successfully loaded ckeckpoint – {last_ckpt}\\n')\n",
    "        sys.stdout.flush()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f'WARN: Could not load checkpoint. {e}\\n')\n",
    "        sys.stderr.flush()\n",
    "else:\n",
    "    tf.gfile.MakeDirs(model_dir)\n",
    "    sys.stdout.write(f'Created checkpoint directory — {model_dir}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "epsilon = 0.1\n",
    "episodes = 10000\n",
    "max_trans_per_episode = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\tGlobal steps: 259,396\tWins: 1\tNum transistions: 49\tTotal reward: 0.0\n",
      "Episode: 1,001\tGlobal steps: 288,562\tWins: 817\tNum transistions: 10\tTotal reward: 1.0\n",
      "Episode: 2,001\tGlobal steps: 316,607\tWins: 1,632\tNum transistions: 36\tTotal reward: 1.0\n",
      "Episode: 2,365\tGlobal steps: 327,256\tWins: 1,925\tNum transistions: 27\tTotal reward: 1.0"
     ]
    }
   ],
   "source": [
    "total_reward, wins = 0, 0\n",
    "for episode in range(episodes):\n",
    "    state, done = env.reset(), False\n",
    "    max_trans = 0\n",
    "    \n",
    "    while max_trans < max_trans_per_episode:\n",
    "        max_trans += 1\n",
    "        action, Q = sess.run([predict, Q_value], \n",
    "                             feed_dict={inputs: one_hot(n_states, state)})\n",
    "        # Epsilon Greedy Exploration\n",
    "        if np.random.randn(1) < epsilon:\n",
    "            action[0] = env.action_space.sample()\n",
    "        # Take the action\n",
    "        new_state, reward, done, _ = env.step(action[0])\n",
    "        # Get Q´ values for the next_state\n",
    "        new_Q = sess.run(Q_value, feed_dict={inputs: one_hot(n_states, new_state)})\n",
    "        Q[0, action[0]] = reward + gamma * np.max(new_Q)\n",
    "        # Train network\n",
    "        _, _i_global = sess.run([train, global_step], \n",
    "                                feed_dict={inputs: one_hot(n_states, state), target: Q})\n",
    "        state = new_state\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            wins += 1\n",
    "            sys.stdout.write(f'\\rEpisode: {episode+1:,}\\tGlobal steps: {_i_global:,}\\tWins: {wins:,}\\t'\n",
    "                             f'Num transistions: {max_trans:,}\\tTotal reward: {total_reward}')\n",
    "            sys.stdout.flush()\n",
    "            break\n",
    "    if episode % 1000 == 0:\n",
    "        saver.save(sess=sess, save_path=model_path, global_step=global_step)\n",
    "        summary = sess.run(merged, feed_dict={inputs: one_hot(n_states, state), target: Q})\n",
    "        writer.add_summary(summary=summary, global_step=_i_global)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
